双通信栈原因：
UDP通信栈
- 当前企业的数据中心仍依赖以太网，基于 IP 的协议栈仍被企业数据中心的许多应用程序广泛使用
- 可直接通过 IPoIB 在高速网络
RDMA 通信栈
- IPoIB实际上并未绕过传统网络协议栈，原生支持 RDMA 以提供更高的性能表现

- 支持超大规模内存
1 EB（Exabyte，艾字节）规模 = 1024 PB
1 PB（Petabyte，拍字节）规模 = 1024 TB
1 TB（Terabyte，太字节）规模 = 1024 GB（千兆字节）
64位架构理论内存上限 2^64 字节 = 16 EB；
当前典型实现（48位寻址）：2^48 字节 = 256 TB
扩展实现：2^57 字节 = 128 PB
当前单个高端服务器支持的最大内存（RAM）大约为 10TB~20TB。
原因：
1. 物理内存插槽限制，服务器主板上的内存插槽数量有限
2. 内存模块密度：单个内存模块的最大容量有限
3. 内存控制器限制
4. 散热与功耗挑战：大量内存带来严重的散热和功耗问题，需要更复杂的冷却系统和电源供应。
5. 成本高昂，

- 配置简单（仅依赖必要库），支持原生 RDMA RC 连接


环境：千兆以太网

| 机器         | 型号                                       | IP             | 子网              |
| ---------- | ---------------------------------------- | -------------- | --------------- |
| cpuserver1 | Intel® Xeon® Gold 6338 CPU @ 2.000GHz    | 10.208.130.245 | 10.208.130.0/24 |
| cpuserver2 | Intel® Xeon® Gold 6338 CPU @ 2.000GHz    | 10.208.130.247 | 10.208.130.0/24 |
| cpuserver3 | Intel® Xeon® Gold 6338 CPU @ 2.000GHz    | 10.208.130.249 | 10.208.130.0/24 |
| cpuserver4 | Intel® Xeon® Platinum 8176 CPU @ 2.10GHz | 10.208.129.87  | 10.208.129.0/24 |
| cpuserver5 | Intel® Xeon® Platinum 8176 CPU @ 2.10GHz | 10.208.129.89  | 10.208.129.0/24 |
| cpuserver6 | Intel® Xeon® Platinum 8176 CPU @ 2.10GHz | 10.208.129.90  | 10.208.129.0/24 |
| cpuserver7 | AMD EPYC 9654 96-Core Processor          | 10.208.130.172 | 10.208.130.0/24 |
| cpuserver8 | AMD EPYC 9754 128-Core Processor         | 10.208.130.174 | 10.208.130.0/24 |
性能测试
单线程测试：大量平方运算（1~10000000）
多线程测试：8线程大量平方运算（1~10000000）
内存带宽：简单计算模拟内存带宽

| 机器         | 单线程    | 多线程    | 内存带宽          |
| ---------- | ------ | ------ | ------------- |
| cpuserver1 | 0.9908 | 0.1239 | 7476.50 MB/s  |
| cpuserver2 | 0.9953 | 0.1233 | 10842.98 MB/s |
| cpuserver3 | 0.9919 | 0.1239 | 7461.79 MB/s  |
| cpuserver4 | 1.0400 | 0.1322 | 9997.39 MB/s  |
| cpuserver5 | 1.0363 | 0.1323 | 10101.06 MB/s |
| cpuserver6 | 1.0276 | 0.1321 | 9752.52 MB/s  |
| cpuserver7 | 0.5112 | 0.0556 | 26543.88 MB/s |
| cpuserver8 | 4.7245 | 0.5102 | 5677.15 MB/s  |

为什么不使用 OpenMPI 作为后端
OpenMPI 的依赖太多（如PMIx和UCX），其中对版本匹配有较高要求，可移植性并没有那么强。
UCX 并不支持 UDP 通信。